import streamlit as st
from src.agent.sandbox import generate_graph  # ã‚ãªãŸã®LangGraphç”Ÿæˆé–¢æ•°

# LangGraphç”¨
from langgraph.graph import StateGraph

# åˆæœŸåŒ–å‡¦ç†
if "graph" not in st.session_state:
    st.session_state.graph = generate_graph()
    st.session_state.graph_stream = st.session_state.graph.stream({}, debug=False)
    st.session_state.state = None  # LangGraphã®ç¾åœ¨ã®state
    st.session_state.await_user = False  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±å¾…ã¡ã‹ã©ã†ã‹

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’è¡¨ç¤º
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# LangGraphã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’é€²ã‚ã‚‹ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›å¾…ã¡ã§ãªã„ã¨ãï¼‰
if not st.session_state.await_user:
    for nested_dict in st.session_state.graph_stream:
        current_node = next(iter(nested_dict))
        state = nested_dict[current_node]
        st.session_state.state = state  # æœ€æ–°ãƒãƒ¼ãƒ‰çŠ¶æ…‹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜

        if current_node == "generate_question":
            # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æœ€æ–°ç™ºè©±ã‚’å–ã‚Šå‡ºã™
            agent_reply = state["agent_reply"]
            st.session_state.messages.append({"role": "assistant", "content": agent_reply})
            with st.chat_message("assistant"):
                st.markdown(agent_reply)

            # ãƒãƒ¼ãƒ‰ï¼‘ã¤å®Ÿè¡Œã§ãƒ«ãƒ¼ãƒ—æŠœã‘ã‚‹
            break

        elif current_node == "user_action":
            # ã“ã“ã§å…¥åŠ›å¾…ã¡ã«ã™ã‚‹
            st.session_state.await_user = True
            break

        elif current_node == "judge_result":
            st.write("judge_result ãƒãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã—ãŸ")
            st.write("ç¾åœ¨ã® history:", state["history"])
            # ã“ã“ã§ã‚‚ï¼‘ã‚¹ãƒ†ãƒƒãƒ—ã§æŠœã‘ã‚‹
            break

        elif current_node == "end_node":
            st.success("ãƒ’ã‚¢ãƒªãƒ³ã‚°å®Œäº† ğŸ‰")
            break

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ¬„
prompt = st.chat_input("ã‚ãªãŸã®è¿”ç­”ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
if prompt:
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¡¨ç¤º
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # **ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ LangGraph ã® state ã«æ ¼ç´** (ã€Œæ˜ç¤ºçš„ã«ä»£å…¥ã™ã‚‹ã€æ–¹æ³•)
    if st.session_state.state:
        st.session_state.state["user_input"] = prompt
    else:
        # ã¾ã åˆæœŸåŒ–ã•ã‚Œã¦ã„ãªã„å ´åˆã¯é©å®œå‡¦ç†
        st.session_state.state = {}
        st.session_state.state["user_input"] = prompt

    # ãƒãƒ¼ãƒ‰ã‚’å†é–‹ï¼ˆuser_actionãƒãƒ¼ãƒ‰ã‚’é€²ã‚ãŸã„ï¼‰
    print("=== state_send ===")
    print(st.session_state.state)
    st.session_state.graph_stream.send(st.session_state.state)

    # å…¥åŠ›å¾…ã¡çŠ¶æ…‹ã‚’è§£é™¤ã—ã¦å†æç”»
    st.session_state.await_user = False
    st.rerun()
